/**
 * Answer Generation Performance Load Testing
 * Feature 009: Answer Generation with LLM - Final Phase
 *
 * Tests:
 * - T263: Load testing with 100 concurrent requests
 * - T264: P95 latency <2s for uncached requests
 * - T265: P95 latency <100ms for cached requests
 *
 * Usage:
 *   node tests/performance/answer-generation-load-test.js
 */

/**
 * Test Configuration
 */
const TEST_CONFIG = {
  // Number of concurrent requests
  concurrency: 100,

  // Number of unique queries (affects cache hit rate)
  uniqueQueries: 30,

  // Target latency thresholds (milliseconds)
  targetUncachedP95: 2000, // 2 seconds
  targetCachedP95: 100,    // 100 milliseconds

  // API endpoint (local dev server or production)
  apiEndpoint: process.env.API_ENDPOINT || 'http://localhost:8787',

  // Test JWT token (create a test user first)
  jwtToken: process.env.TEST_JWT_TOKEN || 'your-test-jwt-token-here'
};

/**
 * Sample test queries (mix of different query types)
 */
const SAMPLE_QUERIES = [
  // Entity description
  { question: 'Who is Sarah Johnson?', type: 'entity' },
  { question: 'Tell me about the FastAPI project', type: 'entity' },

  // Relationship queries
  { question: 'What projects is Sarah working on?', type: 'relationship' },
  { question: 'Who did I meet with last week?', type: 'relationship' },

  // Temporal queries
  { question: 'What did I do yesterday?', type: 'temporal' },
  { question: 'What meetings happened in November?', type: 'temporal' },

  // Count queries
  { question: 'How many projects involve Python?', type: 'count' },
  { question: 'How many people did I meet this month?', type: 'count' },

  // List queries
  { question: 'List all my active projects', type: 'list' },
  { question: 'Show me all meetings with Bob', type: 'list' },

  // Empty result queries
  { question: 'Who is John Doe?', type: 'empty' },
  { question: 'Tell me about the XYZ project', type: 'empty' },

  // Complex queries
  { question: 'What is the status of the Redis migration project?', type: 'complex' },
  { question: 'When did Sarah start working on the API redesign?', type: 'complex' },

  // Additional diverse queries for load testing
  { question: 'What technologies am I using?', type: 'list' },
  { question: 'Who are my team members?', type: 'list' },
  { question: 'What were the key takeaways from my standup?', type: 'complex' },
  { question: 'How many meetings did I have last week?', type: 'count' },
  { question: 'What is the deadline for the migration project?', type: 'entity' },
  { question: 'Who is leading the GraphQL initiative?', type: 'relationship' },
  { question: 'What did we discuss in the November 5th meeting?', type: 'temporal' },
  { question: 'List all projects using TypeScript', type: 'list' },
  { question: 'How many people work on the backend team?', type: 'count' },
  { question: 'What is Alice working on?', type: 'relationship' },
  { question: 'Tell me about the caching optimization project', type: 'entity' },
  { question: 'When was the last deployment?', type: 'temporal' },
  { question: 'Who attended the Q4 planning meeting?', type: 'list' },
  { question: 'How many bugs were fixed this sprint?', type: 'count' },
  { question: 'What is the status of the documentation updates?', type: 'entity' },
  { question: 'What meetings are scheduled for next week?', type: 'temporal' }
];

/**
 * Statistics tracking
 */
class PerfStats {
  constructor() {
    this.latencies = [];
    this.cachedLatencies = [];
    this.uncachedLatencies = [];
    this.errors = [];
    this.startTime = null;
    this.endTime = null;
  }

  recordLatency(latencyMs, cached = false) {
    this.latencies.push(latencyMs);
    if (cached) {
      this.cachedLatencies.push(latencyMs);
    } else {
      this.uncachedLatencies.push(latencyMs);
    }
  }

  recordError(error) {
    this.errors.push(error);
  }

  calculatePercentile(arr, percentile) {
    if (arr.length === 0) return 0;
    const sorted = [...arr].sort((a, b) => a - b);
    const index = Math.ceil((percentile / 100) * sorted.length) - 1;
    return sorted[index];
  }

  getReport() {
    const totalDuration = this.endTime - this.startTime;
    const totalRequests = this.latencies.length;
    const throughput = (totalRequests / (totalDuration / 1000)).toFixed(2);

    return {
      summary: {
        totalRequests,
        totalErrors: this.errors.length,
        errorRate: ((this.errors.length / totalRequests) * 100).toFixed(2) + '%',
        totalDuration: totalDuration + 'ms',
        throughput: throughput + ' req/s'
      },
      latency: {
        all: {
          p50: this.calculatePercentile(this.latencies, 50),
          p95: this.calculatePercentile(this.latencies, 95),
          p99: this.calculatePercentile(this.latencies, 99),
          avg: (this.latencies.reduce((a, b) => a + b, 0) / this.latencies.length).toFixed(2),
          min: Math.min(...this.latencies),
          max: Math.max(...this.latencies)
        },
        uncached: this.uncachedLatencies.length > 0 ? {
          count: this.uncachedLatencies.length,
          p50: this.calculatePercentile(this.uncachedLatencies, 50),
          p95: this.calculatePercentile(this.uncachedLatencies, 95),
          p99: this.calculatePercentile(this.uncachedLatencies, 99),
          avg: (this.uncachedLatencies.reduce((a, b) => a + b, 0) / this.uncachedLatencies.length).toFixed(2)
        } : { count: 0, message: 'No uncached requests' },
        cached: this.cachedLatencies.length > 0 ? {
          count: this.cachedLatencies.length,
          p50: this.calculatePercentile(this.cachedLatencies, 50),
          p95: this.calculatePercentile(this.cachedLatencies, 95),
          p99: this.calculatePercentile(this.cachedLatencies, 99),
          avg: (this.cachedLatencies.reduce((a, b) => a + b, 0) / this.cachedLatencies.length).toFixed(2)
        } : { count: 0, message: 'No cached requests' },
        cacheHitRate: ((this.cachedLatencies.length / totalRequests) * 100).toFixed(2) + '%'
      },
      validation: {
        uncachedP95Pass: this.uncachedLatencies.length > 0
          ? this.calculatePercentile(this.uncachedLatencies, 95) < TEST_CONFIG.targetUncachedP95
          : null,
        cachedP95Pass: this.cachedLatencies.length > 0
          ? this.calculatePercentile(this.cachedLatencies, 95) < TEST_CONFIG.targetCachedP95
          : null
      }
    };
  }
}

/**
 * Simulate answer generation request
 * Note: This is a mock implementation. Replace with actual API calls.
 */
async function generateAnswer(question, cached = false) {
  const startTime = Date.now();

  try {
    // TODO: Replace with actual API call to your answer generation endpoint
    // Example:
    // const response = await fetch(`${TEST_CONFIG.apiEndpoint}/api/query/answer`, {
    //   method: 'POST',
    //   headers: {
    //     'Authorization': `Bearer ${TEST_CONFIG.jwtToken}`,
    //     'Content-Type': 'application/json'
    //   },
    //   body: JSON.stringify({ question })
    // });
    // const data = await response.json();

    // Mock delay based on cached status
    const mockDelay = cached ? Math.random() * 80 + 20 : Math.random() * 1000 + 1000;
    await new Promise(resolve => setTimeout(resolve, mockDelay));

    const latency = Date.now() - startTime;

    return {
      success: true,
      latency,
      cached,
      answer: `Mock answer for: ${question}`
    };
  } catch (error) {
    return {
      success: false,
      error: error.message,
      latency: Date.now() - startTime
    };
  }
}

/**
 * Run load test
 */
async function runLoadTest() {
  console.log('üöÄ Answer Generation Load Test Starting...\n');
  console.log(`Configuration:`);
  console.log(`  - Concurrent requests: ${TEST_CONFIG.concurrency}`);
  console.log(`  - Unique queries: ${TEST_CONFIG.uniqueQueries}`);
  console.log(`  - Target uncached p95: <${TEST_CONFIG.targetUncachedP95}ms`);
  console.log(`  - Target cached p95: <${TEST_CONFIG.targetCachedP95}ms\n`);

  const stats = new PerfStats();
  stats.startTime = Date.now();

  // Phase 1: Prime the cache (send each unique query once)
  console.log('üì¶ Phase 1: Priming cache...');
  const uniqueQueries = SAMPLE_QUERIES.slice(0, TEST_CONFIG.uniqueQueries);

  for (const query of uniqueQueries) {
    const result = await generateAnswer(query.question, false);
    if (result.success) {
      stats.recordLatency(result.latency, false);
    } else {
      stats.recordError(result.error);
    }
  }
  console.log(`   ‚úÖ Primed ${uniqueQueries.length} queries\n`);

  // Phase 2: Load test with mix of cached and uncached requests
  console.log('üî• Phase 2: Load testing with 100 concurrent requests...');

  const requests = [];
  for (let i = 0; i < TEST_CONFIG.concurrency; i++) {
    // Mix: 60% cached (repeat from unique set), 40% uncached (new or expired)
    const isCached = Math.random() < 0.6;
    const query = uniqueQueries[Math.floor(Math.random() * uniqueQueries.length)];

    requests.push(
      generateAnswer(query.question, isCached)
        .then(result => {
          if (result.success) {
            stats.recordLatency(result.latency, result.cached);
          } else {
            stats.recordError(result.error);
          }
        })
    );
  }

  await Promise.all(requests);
  stats.endTime = Date.now();

  console.log(`   ‚úÖ Completed ${TEST_CONFIG.concurrency} requests\n`);

  // Generate report
  const report = stats.getReport();

  console.log('üìä Performance Report:\n');
  console.log('Summary:');
  console.log(`  - Total Requests: ${report.summary.totalRequests}`);
  console.log(`  - Total Errors: ${report.summary.totalErrors}`);
  console.log(`  - Error Rate: ${report.summary.errorRate}`);
  console.log(`  - Duration: ${report.summary.totalDuration}`);
  console.log(`  - Throughput: ${report.summary.throughput}\n`);

  console.log('Latency (All Requests):');
  console.log(`  - P50: ${report.latency.all.p50}ms`);
  console.log(`  - P95: ${report.latency.all.p95}ms`);
  console.log(`  - P99: ${report.latency.all.p99}ms`);
  console.log(`  - Avg: ${report.latency.all.avg}ms`);
  console.log(`  - Min: ${report.latency.all.min}ms`);
  console.log(`  - Max: ${report.latency.all.max}ms\n`);

  if (report.latency.uncached.count > 0) {
    console.log(`Latency (Uncached Requests - ${report.latency.uncached.count} requests):`);
    console.log(`  - P50: ${report.latency.uncached.p50}ms`);
    console.log(`  - P95: ${report.latency.uncached.p95}ms ${report.validation.uncachedP95Pass ? '‚úÖ' : '‚ùå'}`);
    console.log(`  - P99: ${report.latency.uncached.p99}ms`);
    console.log(`  - Avg: ${report.latency.uncached.avg}ms\n`);
  }

  if (report.latency.cached.count > 0) {
    console.log(`Latency (Cached Requests - ${report.latency.cached.count} requests):`);
    console.log(`  - P50: ${report.latency.cached.p50}ms`);
    console.log(`  - P95: ${report.latency.cached.p95}ms ${report.validation.cachedP95Pass ? '‚úÖ' : '‚ùå'}`);
    console.log(`  - P99: ${report.latency.cached.p99}ms`);
    console.log(`  - Avg: ${report.latency.cached.avg}ms\n`);
  }

  console.log(`Cache Hit Rate: ${report.latency.cacheHitRate}\n`);

  // Validation summary
  console.log('üéØ Validation Results:');
  if (report.validation.uncachedP95Pass !== null) {
    console.log(`  - Uncached P95 < 2s: ${report.validation.uncachedP95Pass ? '‚úÖ PASS' : '‚ùå FAIL'}`);
  }
  if (report.validation.cachedP95Pass !== null) {
    console.log(`  - Cached P95 < 100ms: ${report.validation.cachedP95Pass ? '‚úÖ PASS' : '‚ùå FAIL'}`);
  }

  const allPass = (report.validation.uncachedP95Pass !== false) && (report.validation.cachedP95Pass !== false);
  console.log(`\n${allPass ? '‚úÖ All performance targets met!' : '‚ö†Ô∏è  Some performance targets not met'}`);

  return allPass;
}

/**
 * Main execution
 */
if (import.meta.url === `file://${process.argv[1]}`) {
  runLoadTest()
    .then(success => {
      process.exit(success ? 0 : 1);
    })
    .catch(error => {
      console.error('‚ùå Load test failed:', error);
      process.exit(1);
    });
}

export { runLoadTest, TEST_CONFIG, SAMPLE_QUERIES };
